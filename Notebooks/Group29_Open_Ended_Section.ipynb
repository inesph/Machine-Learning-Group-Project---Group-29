{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fcda83-44f5-48af-80a1-4ba380d3faec",
   "metadata": {},
   "source": [
    "# Students ID\n",
    "\n",
    "Student Name - Inês Honrado<br>\n",
    "Student id - 20240559<br>\n",
    "Contact e-mail - 20240559@novaims.unl.pt<br>\n",
    "\n",
    "Student Name - Jude Gbenimako<br>\n",
    "Student id - 20240700<br>\n",
    "Contact e-mail - 20240700@novaims.unl.pt<br>\n",
    "\n",
    "Student Name - Rúben Marques<br>\n",
    "Student id - 20240352<br>\n",
    "Contact e-mail - 20240352@novaims.unl.pt<br>\n",
    "\n",
    "Student Name - Susana Reis<br>\n",
    "Student id - 20240567<br>\n",
    "Contact e-mail - 20240567@novaims.unl.pt<br>\n",
    "\n",
    "Student Name - Tomás Carvalho<br>\n",
    "Student id - 20240938<br>\n",
    "Contact e-mail - 20240938@novaims.unl.pt<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c5d71-f497-449c-88c6-ca986f6071ea",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022058f-3abf-4b2f-ac59-9c5d2c131b63",
   "metadata": {},
   "source": [
    "Workers' compensation for workplace injuries in New York are administrated through the Workers' Compensation Board. Due to the fact that over 5 million claims have been processed since the year 2000, assessing claims manually is very time-consuming. The purpose of this project is to apply machine learning models, taking claims from 2020 to 2022, to conduct automated claim evaluations in order to seep up decision-making on new claims and increase WCB efficiency in handling compensation processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a0edb-0ea8-45f5-8391-0a5438605f76",
   "metadata": {},
   "source": [
    "# Open-Ended Section: Streamlit Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d95174-cbc8-42c1-bab3-3c577074afc9",
   "metadata": {},
   "source": [
    "In this final section, we have developed an intuitive **Streamlit** interface. This user-friendly tool will allow non-technical users to input essential claim details and instantly receive predictions on the likely **Claim Injury Type**. \n",
    "\n",
    "### Key Features:\n",
    "1. **Easy Data Input**: The user will fill in key claim details (the include variables).\n",
    "   \n",
    "2. **Instant Predictions**: Once the required fields are filled, the user can click on a \"Predict\" button to get the **Claim Injury Type** prediction. This process requires no technical knowledge, making it simple and fast for the user.\n",
    "\n",
    "3. **Confidence Score**: After displaying the prediction, the model will also show a confidence score, giving staff insight into the model's certainty regarding the prediction.\n",
    "\n",
    "4. **Feature Importance**: For further transparency, the interface will show which features most influenced the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caefc34e-93fc-448c-a4d5-0622d818177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_code = \"\"\"\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model_path = 'final_model.pkl'\n",
    "scaler_path = 'scaler.pkl'\n",
    "encoder_path = 'target_encoder.pkl'\n",
    "label_path = 'label_encoder.pkl'\n",
    "\n",
    "final_model = joblib.load(model_path)\n",
    "scaler = joblib.load(scaler_path)\n",
    "target_encoder = joblib.load(encoder_path)\n",
    "label_encoder = joblib.load(label_path)\n",
    "\n",
    "include_variables = [\n",
    "    'Attorney/Representative',\n",
    "    'Average Weekly Wage',\n",
    "    'Birth Year',\n",
    "    'Carrier Name',\n",
    "    'Carrier Type',\n",
    "    'IME-4 Count',\n",
    "    'Industry Code',\n",
    "    'Medical Fee Region',\n",
    "    'WCIO Cause of Injury Code',\n",
    "    'WCIO Nature of Injury Code',\n",
    "    'WCIO Part Of Body Code',\n",
    "    'Zip Code',\n",
    "    'Agreement Reached',\n",
    "    'C-3 Received',\n",
    "    'First Hearing Happened',\n",
    "    'Time to Assembly'\n",
    "]\n",
    "\n",
    "\n",
    "left_col_features = [\n",
    "    'Average Weekly Wage',\n",
    "    'Birth Year',\n",
    "    'Carrier Name',\n",
    "    'Carrier Type',\n",
    "    'Industry Code',\n",
    "    'Zip Code',\n",
    "    'IME-4 Count',\n",
    "    'Medical Fee Region',\n",
    "]\n",
    "\n",
    "right_col_features = [\n",
    "    'Attorney/Representative',\n",
    "    'Time to Assembly',\n",
    "    'WCIO Cause of Injury Code',\n",
    "    'WCIO Nature of Injury Code',\n",
    "    'WCIO Part Of Body Code',\n",
    "    'Agreement Reached',\n",
    "    'C-3 Received',\n",
    "    'First Hearing Happened'\n",
    "]\n",
    "\n",
    "st.title(\"Model Prediction App\")\n",
    "st.write(\"Welcome to the prediction app! You can make predictions using the trained model.\")\n",
    "\n",
    "st.subheader(\"Enter the Values for Prediction\")\n",
    "input_data = {}\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    for feature in left_col_features:\n",
    "        if feature in ['Zip Code']:\n",
    "            input_data[feature] = st.text_input(feature, \"\").zfill(5)\n",
    "        elif feature in ['Birth Year']:\n",
    "            input_data[feature] = st.text_input(feature, \"\").zfill(4)\n",
    "        elif feature in ['Carrier Name', 'Carrier Type', 'Medical Fee Region']:\n",
    "            input_data[feature] = st.text_input(feature, \"\").upper()\n",
    "        elif feature in ['Average Weekly Wage', 'IME-4 Count']:\n",
    "            input_data[feature] = st.number_input(feature, value=0.0)\n",
    "        else:\n",
    "            input_data[feature] = st.number_input(feature, value=0)\n",
    "\n",
    "with col2:\n",
    "    for feature in right_col_features:\n",
    "        if feature in ['Attorney/Representative', 'Agreement Reached', 'C-3 Received', 'First Hearing Happened']:\n",
    "            input_data[feature] = st.number_input(f\"{feature} (0 for No and 1 for Yes)\", min_value=0, max_value=1, step=1)\n",
    "        else:\n",
    "            input_data[feature] = st.number_input(feature, value=0)\n",
    "\n",
    "            \n",
    "if st.button(\"Predict\"):\n",
    "    with st.spinner(\"Making prediction...\"):\n",
    "        input_df = pd.DataFrame([input_data], columns=include_variables)\n",
    "\n",
    "        encoder_features = target_encoder.feature_names_in_\n",
    "        \n",
    "        for feature in encoder_features:\n",
    "            if feature not in input_df.columns:\n",
    "                input_df[feature] = \"\"\n",
    "\n",
    "        cols_to_enc = [\n",
    "            'Carrier Name', 'Carrier Type', 'County of Injury', 'Industry Code', \n",
    "            'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', \n",
    "            'WCIO Part Of Body Code', 'District Name', \n",
    "            'Gender', 'Medical Fee Region', 'Zip Code', 'Injury Day of Week'\n",
    "        ] \n",
    "        \n",
    "        input_df[cols_to_enc] = target_encoder.transform(input_df[cols_to_enc])\n",
    "\n",
    "        scaler_features = scaler.feature_names_in_\n",
    "\n",
    "        for feature in scaler_features:\n",
    "            if feature not in input_df.columns:\n",
    "                input_df[feature] = 0\n",
    "\n",
    "        input_df = input_df[scaler_features]\n",
    "        \n",
    "        scaled_input = scaler.transform(input_df)\n",
    "        scaled_input_df = pd.DataFrame(scaled_input, columns=scaler.feature_names_in_)\n",
    "        \n",
    "        input_df_for_pred = scaled_input_df[include_variables]\n",
    "        \n",
    "        encoded_prediction = final_model.predict(input_df_for_pred)\n",
    "        prediction = label_encoder.inverse_transform(encoded_prediction)\n",
    "\n",
    "        if hasattr(final_model, \"predict_proba\"):\n",
    "            probabilities = final_model.predict_proba(input_df_for_pred)\n",
    "            confidence_score = probabilities.max(axis=1)[0]\n",
    "\n",
    "        st.success(\"Prediction Complete!\")\n",
    "        st.write(f\"Prediction: {prediction[0]}\")  \n",
    "\n",
    "        if hasattr(final_model, \"predict_proba\"):\n",
    "            st.metric(label=\"Confidence Score\", value=f\"{confidence_score * 100:.2f}%\")\n",
    "\n",
    "        rf_model = final_model.named_estimators_['rf']\n",
    "        rf_feature_importances = rf_model.feature_importances_\n",
    "\n",
    "        feature_importances_df = pd.DataFrame({\n",
    "            'Feature': input_df_for_pred.columns,\n",
    "            'Importance': rf_feature_importances\n",
    "        })\n",
    "\n",
    "        # Sorting the feature importances\n",
    "        feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        # Display the top feature importances\n",
    "        st.write(\"Top Feature Importances from RandomForestClassifier:\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.bar(feature_importances_df['Feature'], feature_importances_df['Importance'])\n",
    "        ax.set_xlabel('Feature')\n",
    "        ax.set_ylabel('Importance')\n",
    "        plt.xticks(rotation=45, ha='right')  # Rotate labels\n",
    "        st.pyplot(fig)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb34353-b91c-4273-9b82-446b5a7ac484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py has been created!\n"
     ]
    }
   ],
   "source": [
    "with open(\"app.py\", \"w\") as file:\n",
    "    file.write(app_code)\n",
    "\n",
    "print(\"app.py has been created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee725fe-9396-433e-b0ca-9386e9f9662a",
   "metadata": {},
   "source": [
    "Once the app.py file is created, you need to run the application. Before that, make sure that the following files are all stored in the same directory as your command prompt or terminal:\n",
    "\n",
    "   - `app.py`\n",
    "   - `final_model.pkl`\n",
    "   - `scaler.pkl`\n",
    "   - `target_encoder.pkl`\n",
    "   - `label_encoder.pkl`\n",
    "\n",
    "After ensuring that these files are in the same directory, open your command prompt or terminal, navigate to that directory, and run the following command to start the Streamlit app:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1407ccf2-9019-46de-ab8b-a44aa195ca80",
   "metadata": {},
   "source": [
    "streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d5c13-6627-43f1-aefe-41138861f44b",
   "metadata": {},
   "source": [
    "This will launch the application, and you'll be able to use the interface to make predictions! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
